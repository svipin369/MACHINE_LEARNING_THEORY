{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee52d06",
   "metadata": {},
   "source": [
    "# Assignment_15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4e9b9",
   "metadata": {},
   "source": [
    "Question 1. Recognize the differences between supervised, semi-supervised, and unsupervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebccb19",
   "metadata": {},
   "source": [
    "Answer 1) Supervised learning aims to learn a function that, given a sample of data and desired outputs, approximates a function\n",
    "that maps inputs to outputs.\n",
    " \n",
    " Semi-supervised learning aims to label unlabeled data points using knowledge learned from a small number of labeled \n",
    "data points.\n",
    "\n",
    "Unsupervised learning does not have (or need) any labeled outputs, so its goal is to infer the natural structure \n",
    " present within a set of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a92da5",
   "metadata": {},
   "source": [
    "Question 2. Describe in detail any five examples of classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44d825f",
   "metadata": {},
   "source": [
    "Ans 2): \n",
    "5 Examples of Classification Problems : \n",
    "Logistic regression : Logistic regression is a supervised learning classification algorithm used to predict the \n",
    "probability of a target variable. ... It is one of the simplest ML algorithms that can be used \n",
    "for various classification problems such as spam detection, Diabetes prediction, cancer detection\n",
    "etc.\n",
    "\n",
    "Decision trees : Decision Trees are a type of Supervised Machine Learning (that is you explain what the input is and \n",
    " what the corresponding output is in the training data) where the data is continuously split according\n",
    "to a certain parameter. The tree can be explained by two entities, namely decision nodes and leaves.\n",
    "\n",
    "Random forest : Random forest is a Supervised Machine Learning Algorithm that is used widely in Classification and\n",
    "\n",
    "Regression problems. It builds decision trees on different samples and takes their majority vote for \n",
    "classification and average in case of regression. It performs better results for classification\n",
    "problems.\n",
    "\n",
    "XGBoost : XGBoost is an algorithm that has recently been dominating applied machine learning and Kaggle competitions\n",
    "for structured or tabular data. XGBoost is an implementation of gradient boosted decision trees designed for\n",
    "speed and performance.Why XGBoost must be a part of your machine learning toolkit.\n",
    "\n",
    "Light GBM : Light Gradient Boosted Machine, or LightGBM for short, is an open-source library that provides an efficient\n",
    "and effective implementation of the gradient boosting algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37833ec",
   "metadata": {},
   "source": [
    "Question 3. Describe each phase of the classification process in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6158c13",
   "metadata": {},
   "source": [
    " Answer 3) \n",
    " Process of classification consists of two phases : \n",
    " 1. Construction of the classifier; 2. Usage of the classifier.\n",
    " A classifier in machine learning is an algorithm that automatically orders or categorizes data into one or more of a \n",
    "set of “classes.” One of the most common examples is an email classifier that scans emails to filter them by class\n",
    "label: Spam or Not Spam.\n",
    "The main goal of the Classification algorithm is to identify the category of a given dataset, and these algorithms are\n",
    " mainly used to predict the output for the categorical data. Multi-class Classifier: If a classification problem has\n",
    " more than two outcomes, then it is called as Multi-class Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ad927",
   "metadata": {},
   "source": [
    "Question 4. Go through the SVM model in depth using various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5dde2a",
   "metadata": {},
   "source": [
    "Answer 4)\n",
    "\n",
    "“Support Vector Machine” (SVM) is a supervised machine learning algorithm that can be used for both classification or\n",
    "regression challenges. Support Vectors are simply the coordinates of individual observation. The SVM classifier is a \n",
    "frontier that best segregates the two classes (hyper-plane/ line).\n",
    "SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and\n",
    "non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line \n",
    "or a hyperplane which separates the data into classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe8df4",
   "metadata": {},
   "source": [
    "Question 5. What are some of the benefits and drawbacks of SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab4065d",
   "metadata": {},
   "source": [
    "Answer 5)\n",
    "Advantages: SVM works relatively well when there is a clear margin of separation between classes.\n",
    "SVM is more effective in high dimensional spaces.\n",
    "SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "SVM is relatively memory efficient.\n",
    "Disadvantages: SVM algorithm is not suitable for large data sets.\n",
    "SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "In cases where the number of features for each data point exceeds the number of training data samples,\n",
    "the SVM will underperform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ba0c9",
   "metadata": {},
   "source": [
    "Question 6. Go over the kNN model in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8bd6d8",
   "metadata": {},
   "source": [
    "Answer 6) \n",
    "kNN is the simplest machine learning algorithm to understand and also to explain. It is a versatile algorithm i.e. \n",
    "useful for both classification and regression. It has one big advantage is that kNN ha no pre assumption about the\n",
    " data. “ Let the data speak for itself ”. \n",
    "The abbreviation KNN stands for “K-Nearest Neighbour”. It is a supervised machine learning algorithm. The algorithm can\n",
    "be used to solve both classification and regression problem statements. The number of nearest neighbours to a new \n",
    " unknown variable that has to be predicted or classified is denoted by the symbol 'K'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3255ac",
   "metadata": {},
   "source": [
    "Question 7. Discuss the kNN algorithm's error rate and validation error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b6e022",
   "metadata": {},
   "source": [
    "Answer 7)\n",
    "\n",
    "The k-Nearest Neighbors (kNN) algorithm is a simple and intuitive classification algorithm, but like any machine learning method, it can have errors associated with its predictions. Two important concepts related to the performance of kNN are the error rate and validation error:\n",
    "\n",
    "Error Rate:\n",
    "\n",
    "The error rate, also known as the misclassification rate, is a measure of how often the kNN algorithm makes incorrect predictions.\n",
    "It is calculated as the number of misclassified data points divided by the total number of data points in the dataset.\n",
    "The error rate is typically expressed as a percentage, where lower values indicate better performance.\n",
    "A lower error rate means that the algorithm is making fewer mistakes in its predictions, indicating higher accuracy.\n",
    "Validation Error:\n",
    "\n",
    "The validation error is a measure of how well the kNN algorithm generalizes to new, unseen data.\n",
    "To estimate the validation error, a dataset is often divided into two subsets: a training set used to train the model and a validation (or test) set used to evaluate its performance.\n",
    "The validation error is calculated as the proportion of misclassified data points in the validation set.\n",
    "It provides an estimate of how well the kNN model will perform on real-world data that it has not seen during training.\n",
    "A low validation error suggests that the kNN model is likely to perform well on new, unseen data, while a high validation error may indicate overfitting or a lack of generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8202b75",
   "metadata": {},
   "source": [
    "Question 8. For kNN, talk about how to measure the difference between the test and training results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1235aa",
   "metadata": {},
   "source": [
    "Answer 8) \n",
    "\n",
    "n k-Nearest Neighbors (kNN), the difference between the test results (predictions) and training results (true labels) is typically measured using a suitable distance metric. The choice of distance metric is crucial, as it determines how the algorithm calculates the similarity or dissimilarity between data points. The most commonly used distance metric in kNN is the Euclidean distance, but other metrics can be chosen based on the nature of the data. Here's how the difference is measured:\n",
    "\n",
    "Euclidean Distance:\n",
    "\n",
    "Euclidean distance is a widely used distance metric for kNN.\n",
    "\n",
    "It measures the straight-line distance between two data points in the feature space.\n",
    "\n",
    "For two data points, A and B, in a D-dimensional space, the Euclidean distance is calculated as:\n",
    "d(A, B) = (x₁ - x₂)² + (y₁ - y₂)²\n",
    "\n",
    "her Distance Metrics:\n",
    "\n",
    "Depending on the type of data and the problem, other distance metrics may be used. Some common alternatives include:\n",
    "Manhattan Distance: This metric measures the sum of absolute differences between corresponding features of two data points.\n",
    "\n",
    "Minkowski Distance: A generalization of both Euclidean and Manhattan distances, where you can adjust a parameter \"p\" to control the degree of similarity.\n",
    "\n",
    "Cosine Similarity: Often used for text data or high-dimensional data, it measures the cosine of the angle between two vectors representing data points.\n",
    "\n",
    "Choosing the Right Distance Metric:\n",
    "\n",
    "The choice of distance metric should be made based on the characteristics of the data and the problem. For example, Euclidean distance is suitable for continuous numerical data, while cosine similarity may be better for text data.\n",
    "It's important to preprocess and scale the data appropriately before applying the distance metric to ensure that all features contribute equally to the similarity calculation.\n",
    "\n",
    "Distance Threshold:\n",
    "\n",
    "In some cases, practitioners introduce a distance threshold to consider only data points within a certain radius or distance when determining the k nearest neighbors. This can help in reducing the impact of outliers.\n",
    "Weighted kNN:\n",
    "\n",
    "In some variants of kNN, weights are assigned to each neighbor based on their distance to the query point. Closer neighbors may have a higher weight, while farther neighbors have a lower weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b2c0d0",
   "metadata": {},
   "source": [
    "Question 9. Create the kNN algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89f0f95",
   "metadata": {},
   "source": [
    "Answer 9)\n",
    "\n",
    "The k-nearest neighbor algorithm is imported from the scikit-learn package.\n",
    " Create feature and target variables.\n",
    " Split data into training and test data.\n",
    " Generate a k-NN model using neighbors value.\n",
    " Train or fit the data into the model.\n",
    " Predict the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c71ad",
   "metadata": {},
   "source": [
    "Question 10)What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b961bf2",
   "metadata": {},
   "source": [
    "Answer 10)\n",
    "\n",
    "A decision tree is a tree-like model that acts as a decision support tool, visually displaying decisions and their\n",
    " potential outcomes, consequences, and costs. Drawing a decision tree diagram starts from left to right and consists of\n",
    "“burst” nodes that split into different paths.\n",
    " There are three different types of nodes: chance nodes, decision nodes, and end nodes. A chance node, represented by a\n",
    " circle, shows the probabilities of certain results. A decision node, represented by a square, shows a decision to be\n",
    " made, and an end node shows the final outcome of a decision path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312f868c",
   "metadata": {},
   "source": [
    "Question 11. Describe the different ways to scan a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdc5050",
   "metadata": {},
   "source": [
    "Answer 11)\n",
    "\n",
    "In a decision tree analysis, the decision-maker has usually to proceed through the following six steps:\n",
    "\n",
    " a) Define the problem in structured terms.\n",
    " b)Model the decision process.\n",
    " c)Apply the appropriate probability values and financial data.\n",
    " d)“Solve” the decision tree.\n",
    " e)Perform sensitivity analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da4fed",
   "metadata": {},
   "source": [
    "question 12. Describe in depth the decision tree algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b77de",
   "metadata": {},
   "source": [
    "Answer 12)\n",
    "The Decision Tree algorithm is a versatile and widely used machine learning technique for both classification and regression tasks. It's known for its ability to create interpretable models by making a series of decisions based on input features. In this description, we'll dive into the details of the Decision Tree algorithm:\n",
    "\n",
    "Decision Tree Structure:\n",
    "\n",
    "A Decision Tree is a hierarchical structure composed of nodes, where each node represents a decision or a test on one or more input features.\n",
    "There are three types of nodes:\n",
    "Root Node: The topmost node that represents the starting point of the decision tree.\n",
    "Internal Nodes: These nodes represent intermediate decisions and split the data into subsets based on specific conditions.\n",
    "Leaf Nodes (Terminal Nodes): The endpoints of branches, which provide the final prediction or decision.\n",
    "\n",
    "Splitting Criteria:\n",
    "\n",
    "At each internal node, the Decision Tree algorithm selects a feature and a threshold (for numerical features) or a set of categories (for categorical features) to split the data into subsets.\n",
    "The goal is to find the splits that result in subsets with maximum purity or homogeneity. Common measures of purity include Gini impurity and entropy (discussed earlier).\n",
    "For classification tasks, the split aims to reduce the impurity with respect to class labels, while for regression tasks, it minimizes the variance of target values within subsets.\n",
    "\n",
    "Recursive Splitting:\n",
    "\n",
    "The process of selecting features and thresholds to split the data is performed recursively, starting from the root node and continuing until a stopping criterion is met.\n",
    "Stopping criteria can include a maximum tree depth, a minimum number of samples in a node, or reaching a purity threshold.\n",
    "\n",
    "Predictions:\n",
    "\n",
    "To make a prediction for a new data point, it traverses the tree from the root node to a leaf node by following the decisions made at each internal node.\n",
    "For classification tasks, the majority class of data points in the leaf node is assigned as the predicted class label.\n",
    "For regression tasks, the mean or median of the target values in the leaf node is used as the predicted value.\n",
    "\n",
    "Handling Missing Values:\n",
    "\n",
    "Decision Trees can handle missing values in a principled manner by considering alternative paths when a feature's value is missing during prediction.\n",
    "\n",
    "Pruning:\n",
    "\n",
    "Pruning is a technique used to reduce the complexity of a Decision Tree by removing branches that do not significantly improve predictive accuracy on a validation set. This helps prevent overfitting.\n",
    "\n",
    "Feature Importance:\n",
    "\n",
    "Decision Trees can provide a measure of feature importance, indicating which features are most influential in making decisions. This information is valuable for feature selection and understanding the underlying data relationships.\n",
    "\n",
    "Advantages:\n",
    "\n",
    "Decision Trees are easy to understand and interpret, making them suitable for explaining model predictions.\n",
    "They can handle both numerical and categorical data.\n",
    "Decision Trees can capture complex, nonlinear relationships between features and target variables.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Decision Trees are prone to overfitting, especially when they are deep and complex.\n",
    "They can be sensitive to small variations in the data, leading to instability.\n",
    "Creating highly imbalanced trees can result in biased predictions.\n",
    "\n",
    "Ensemble Methods:\n",
    "\n",
    "Decision Trees are often used as base learners in ensemble methods like Random Forests and Gradient Boosting, which combine multiple trees to improve predictive performance and reduce overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d4ebf",
   "metadata": {},
   "source": [
    "Question 13. In a decision tree, what is inductive bias? What would you do to stop overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25129fc4",
   "metadata": {},
   "source": [
    "Answer 13 )The inductive bias (also known as learning bias) of a learning algorithm is the set of assumptions that the learner uses to predict outputs of given inputs that it has not encountered. The kind of necessary assumptions about the nature of\n",
    "the target function are subsumed in the phrase inductive bias.\n",
    "Overfitting makes the model relevant to its data set only, and irrelevant to any other data sets. Some of the methods \n",
    "used to prevent overfitting include ensembling, data augmentation, data simplification, and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adca370",
   "metadata": {},
   "source": [
    "Question 14.Explain advantages and disadvantages of using a decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6596e5c",
   "metadata": {},
   "source": [
    "Answer 14)\n",
    "Advantages and Disadvantages of Decision Trees in Machine Learning. Decision Tree is used to solve both classification\n",
    "and regression problems. But the main drawback of Decision Tree is that it generally leads to overfitting of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002756c7",
   "metadata": {},
   "source": [
    "Question 15. Describe in depth the problems that are suitable for decision tree learning.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a4111",
   "metadata": {},
   "source": [
    "Answer 15)\n",
    "Appropriate Problems for Decision Tree Learning\n",
    "Instances are represented by attribute-value pairs.\n",
    "The target function has discrete output values.\n",
    "Disjunctive descriptions may be required.\n",
    "The training data may contain errors.\n",
    "The training data may contain missing attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce356cd1",
   "metadata": {},
   "source": [
    "Question 16. Describe in depth the random forest model. What distinguishes a random forest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc74ccf",
   "metadata": {},
   "source": [
    "Answer 16) \n",
    "The random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature \n",
    "randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by \n",
    "committee is more accurate than that of any individual tree.\n",
    "The fundamental difference is that in Random forests, only a subset of features are selected at random out of the\n",
    "total and the best split feature from the subset is used to split each node in a tree, unlike in bagging where all \n",
    "features are considered for splitting a node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff36de",
   "metadata": {},
   "source": [
    "Question 17. In a random forest, talk about OOB error and variable value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c74fcb4",
   "metadata": {},
   "source": [
    "In a Random Forest ensemble, two important concepts are the Out-of-Bag (OOB) error and variable importance. Let's delve into each of these concepts:\n",
    "\n",
    "Out-of-Bag (OOB) Error:\n",
    "\n",
    "The OOB error is a measure of the performance of a Random Forest model without the need for a separate validation set.\n",
    "When constructing each decision tree in the Random Forest, a bootstrap sample (a random sample with replacement) of the training data is used. This means that some data points are left out, and these out-of-bag data points are not used for training the specific tree.\n",
    "\n",
    "The OOB error is calculated by evaluating each data point on the decision trees that were not trained using that specific data point (i.e., the out-of-bag trees). This provides an estimate of how well the model generalizes to unseen data.\n",
    "\n",
    "The OOB error is computed for each data point and then averaged to obtain an overall estimate of the model's performance.\n",
    "\n",
    "The OOB error has several advantages:\n",
    "\n",
    "It provides an unbiased estimate of the model's accuracy without the need for a separate validation set.\n",
    "It helps assess the model's ability to generalize to new, unseen data.\n",
    "It can be used for model selection and hyperparameter tuning.\n",
    "\n",
    "Variable Importance:\n",
    "\n",
    "Variable importance in a Random Forest quantifies the contribution of each feature (variable) to the model's predictive performance.\n",
    "\n",
    "Random Forests measure variable importance by evaluating how much the accuracy of predictions on out-of-bag data points deteriorates when the values of a particular feature are randomly permuted while keeping other features unchanged.\n",
    "Features that, when perturbed, lead to a substantial drop in predictive accuracy are considered more important, as they provide \n",
    "significant information for making predictions.\n",
    "\n",
    "The variable importance scores are typically normalized so that they sum to 1 or 100%, making it easier to compare the relative importance of different features.\n",
    "\n",
    "Variable importance is valuable for:\n",
    "\n",
    "Identifying the most influential features in the dataset, which can guide feature selection and dimensionality reduction.\n",
    "Gaining insights into the factors driving the model's predictions.\n",
    "Assessing which features are redundant or less informative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
