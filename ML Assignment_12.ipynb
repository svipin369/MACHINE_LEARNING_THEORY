{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "naval-ratio",
   "metadata": {},
   "source": [
    "# Assignment_12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-hamilton",
   "metadata": {},
   "source": [
    "Question 1. What is prior probability? Give an example.\n",
    "\n",
    "Answer 1)\n",
    "Prior probability is the probability of an event happening before any new information is considered. It is also known as the initial probability or the subjective probability. Prior probability is based on our existing knowledge and beliefs about the event.\n",
    "Mathematically, it can be defined as the Probability of event A occurring. P(A)\n",
    "\n",
    "Imagine that you are a doctor and you are diagnosing a patient. You have no prior knowledge about the patient's medical history, so you would assign a prior probability to each possible diagnosis based on the prevalence of the disease in the general population.\n",
    "\n",
    "However, if you know that the patient has a family history of the disease, then you would assign a higher prior probability to that diagnosis. This is because you have new information that suggests that the patient is more likely to have the disease.\n",
    "\n",
    "Prior probability is a powerful tool for making informed decisions. It allows us to use our existing knowledge and beliefs to update our beliefs in light of new information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-killer",
   "metadata": {},
   "source": [
    "Question 2. What is posterior probability? Give an example.\n",
    "\n",
    "\n",
    "Answer 2)\n",
    "Posterior probability is the probability of an event happening after new information has been considered. It is also known as the updated probability or the revised probability. Posterior probability is calculated using Bayes' theorem, which is a mathematical formula that updates our beliefs about an event after we have received new information.\n",
    "\n",
    "Here is an example of posterior probability:\n",
    "\n",
    "Imagine that you are flipping a coin. You have no prior knowledge about the coin, so you would assign a prior probability of 0.5 to both heads and tails. This means that you believe that both heads and tails are equally likely to occur.\n",
    "\n",
    "You flip the coin and it lands on heads. This new information updates your beliefs about the coin. You now know that the coin is more likely to land on heads than on tails. You can calculate the posterior probability of heads as follows:\n",
    "\n",
    "Posterior probability of heads = (Prior probability of heads) * (Likelihood of heads given that the coin landed on heads) / (Prior probability of heads * Likelihood of heads given that the coin landed on heads + Prior probability of tails * Likelihood of tails given that the coin landed on heads)\n",
    "\n",
    "Posterior probability of heads = 0.5 * 1 / (0.5 * 1 + 0.5 * 0)\n",
    "Posterior probability of heads = 1\n",
    "This means that after observing the coin land on heads, you are now 100% confident that the coin is more likely to land on heads than on tails.\n",
    "\n",
    "Mathematically, it can be defined as the Probability of event A (P(A)) given that event B has already occurred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-dairy",
   "metadata": {},
   "source": [
    "Question 3. What is likelihood probability? Give an example.\n",
    "\n",
    "\n",
    "Answer 3)\n",
    "Likelihood probability is the probability of observing a particular outcome given a particular model or hypothesis. It is not the same as the probability of the model or hypothesis being true.\n",
    "\n",
    "Here is an example of likelihood probability:\n",
    "\n",
    "Imagine that you are flipping a coin. You have no prior knowledge about the coin, so you would assign a prior probability of 0.5 to both heads and tails. This means that you believe that both heads and tails are equally likely to occur.\n",
    "\n",
    "You flip the coin and it lands on heads. The likelihood of heads given that the coin is fair is 0.5. This means that if the coin is fair, then there is a 50% chance of getting heads.\n",
    "\n",
    "However, if you know that the coin is weighted so that it is more likely to land on heads, then the likelihood of heads given that the coin is weighted is higher than 0.5. This means that if the coin is weighted, then there is a greater than 50% chance of getting heads.\n",
    "\n",
    "Likelihood probability is an important concept in statistics and machine learning. It is used to update our beliefs about a model or hypothesis after we have observed some data. This process is known as maximum likelihood estimation.\n",
    "P(x|c) is the likelihood which is the probability of predictor given class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-found",
   "metadata": {},
   "source": [
    "Question 4. What is Naïve Bayes classifier? Why is it named so?\n",
    "\n",
    "Answer 4)\n",
    "\n",
    "The Naïve Bayes classifier is a simple and probabilistic machine learning algorithm used for classification tasks, particularly in natural language processing (NLP) and text classification. It's based on Bayes' theorem and assumes that the features used for classification are conditionally independent, which is often a simplifying but unrealistic assumption. Despite this simplification, Naïve Bayes can perform surprisingly well in various real-world applications, especially when dealing with text\n",
    "\n",
    "It is named so because this algorithm relies on the assumption that all the features are independent amongst each other.\n",
    "Naive Bayes classifiers are called \"naive\" because they make a strong assumption that the features of a data point are independent of each other. This assumption is often not true in real-world data, but Naive Bayes classifiers can still be very effective for many classification tasks.\n",
    "\n",
    "Naive Bayes classifiers are easy to train and interpret, and they can be used for both text classification and image classification. They are also very scalable, so they can be used to train models on very large datasets.\n",
    "\n",
    "Here is an example of how a Naive Bayes classifier could be used for text classification:\n",
    "\n",
    "Imagine that you want to train a Naive Bayes classifier to classify emails as spam or not spam. You would start by creating a training set of emails, consisting of both spam and not spam emails. You would then extract the features from each email, such as the words in the email, the sender of the email, and the subject line of the email.\n",
    "\n",
    "Once you have extracted the features, you would train the Naive Bayes classifier. The classifier would learn the probability of each feature occurring in spam emails and not spam emails.\n",
    "\n",
    "Once the classifier is trained, you can use it to classify new emails. The classifier would calculate the probability of each feature occurring in the new email, and then use Bayes' theorem to calculate the probability of the email being spam or not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-program",
   "metadata": {},
   "source": [
    "Question 5. What is optimal Bayes classifier?\n",
    "\n",
    "Answer 5)\n",
    "\n",
    "The optimal Bayes classifier is a theoretical classifier that minimizes the probability of error in a classification task. It is based on Bayes' theorem, which is a mathematical formula that updates our beliefs about an event after we have received new information.\n",
    "\n",
    "The optimal Bayes classifier is also known as the maximum a posteriori (MAP) classifier. This is because it chooses the class that has the highest posterior probability given the data.\n",
    "\n",
    "The optimal Bayes classifier is a powerful tool for classification, but it is often difficult to compute in practice. This is because it requires knowledge of the true probability distributions of the data and the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-central",
   "metadata": {},
   "source": [
    "Question 6. Write any two features of Bayesian learning methods.\n",
    "\n",
    "Answer 6)\n",
    "Here are two features of Bayesian learning methods:\n",
    "\n",
    "Bayesian learning methods can update their beliefs in light of new evidence.\n",
    "This is because they use Bayes' theorem, which is a mathematical formula that updates our beliefs about an event after we have received new information. This makes Bayesian learning methods well-suited for tasks where the data is constantly changing, such as spam filtering and fraud detection.\n",
    "\n",
    "Bayesian learning methods can be used to model uncertainty. This is because they produce posterior probabilities, which are the probabilities of different hypotheses given the data. This information can be used to make more informed decisions, and to identify areas where more data is needed.\n",
    "\n",
    "Here are some examples of how these features can be used in real-world applications:\n",
    "\n",
    "Spam filtering: A Bayesian spam filter can learn to identify spam emails by looking at the words in the email, the sender of the email, and the subject line of the email. As the filter receives new data, it can update its beliefs about what features are most likely to be found in spam emails. This makes the filter more accurate over time.\n",
    "\n",
    "Fraud detection: A Bayesian fraud detection system can learn to identify fraudulent transactions by looking at the amount of the transaction, the type of transaction, and the location of the transaction. As the system receives new data, it can update its beliefs about what features are most likely to be found in fraudulent transactions. This makes the system more accurate over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-lease",
   "metadata": {},
   "source": [
    "Question 7. Define the concept of consistent learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-photography",
   "metadata": {},
   "source": [
    "Answer 7)\n",
    "\n",
    "\n",
    "In machine learning, a consistent learner is an algorithm that can learn a concept class from a finite sample of training data, with probability approaching 1 as the sample size increases.\n",
    "\n",
    "A consistent learner is one that can guarantee that it will eventually learn the correct hypothesis, given enough training data. This is in contrast to an inconsistent learner, which may never learn the correct hypothesis, even with an infinite amount of training data.\n",
    "\n",
    "Consistent learners are important because they allow us to learn from data with confidence. If we know that a learning algorithm is consistent, then we can be sure that it will eventually learn the correct hypothesis, given enough training data. This is important for many machine learning tasks, such as spam filtering, fraud detection, and medical diagnosis.\n",
    "\n",
    "Here is an example of a consistent learner:\n",
    "\n",
    "Imagine that you are trying to train a classifier to classify emails as spam or not spam. You have a set of training emails, consisting of both spam and not spam emails. You use a consistent learning algorithm to train the classifier.\n",
    "\n",
    "The consistent learning algorithm will learn to identify spam emails by looking at the words in the email, the sender of the email, and the subject line of the email. As the algorithm receives new data, it will update its beliefs about what features are most likely to be found in spam emails.\n",
    "\n",
    "Eventually, the algorithm will learn to classify emails with high accuracy. This is because the algorithm is a consistent learner, and it is guaranteed to learn the correct hypothesis, given enough training data.\n",
    "\n",
    "Consistent learners are a powerful tool for machine learning, and they are used in a wide variety of applications.\n",
    "\n",
    "Here are some other examples of consistent learners:\n",
    "\n",
    "Support vector machines\n",
    "Decision trees\n",
    "Random forests\n",
    "Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-cooperative",
   "metadata": {},
   "source": [
    "Question 8. Write any two strengths of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-representative",
   "metadata": {},
   "source": [
    "Answer 8)\n",
    "1. It is fast and can be used for real time predictions.\n",
    "    \n",
    " 2. It is easy to implement and comprehend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-liquid",
   "metadata": {},
   "source": [
    "Question 9. Write any two weaknesses of Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-public",
   "metadata": {},
   "source": [
    " Answer 9)\n",
    " 1. Bayesian classifiers are highly impacted by presence of imbalanced data.\n",
    " \n",
    " 2. Since Bayesian classifier starts with an assumption of all features being independent variables, the result can be far from real life in cases. Additionally in terms of mathematics, the algorithm assigns 0 to the target variable class labels that were not present in the training data but are present in test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-military",
   "metadata": {},
   "source": [
    "Question 10. Explain how Naïve Bayes classifier is used for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-sheffield",
   "metadata": {},
   "source": [
    "i) Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-startup",
   "metadata": {},
   "source": [
    "Naive Bayes classifier works by calculating the posterior probability for class labels based on the feature values involved. Suppose that we have to do binary classification in the form a subjective or factual statement and the data preprocessing and data transformation has been performed such that the data is in Bag-Of-Words form as a document term matrix. \n",
    "\n",
    "Using the frequency of each word occurence in a document, the posterior probabilities are calculated using the Naive Bayes algorithm equation and the training is done. After training has been performed, the model can be used to calculate posterior probabilities for unseen data and the class label that gets the highest posterior probabilities is assigned as the prediction. \n",
    "\n",
    "Ultimately, the Naive Bayes classifier predicts probability of a data point if it belongs to one class label or another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-suicide",
   "metadata": {},
   "source": [
    "ii) Spam filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-foster",
   "metadata": {},
   "source": [
    "Spam filtering is a specific type of text classification where the goal is to automatically identify and filter out unwanted or unsolicited emails (spam) from a user's inbox. Naïve Bayes is a popular choice for spam filtering due to its simplicity and effectiveness:\n",
    "\n",
    "Training: During the training phase, the classifier is provided with a labeled dataset of emails, where each email is tagged as spam or non-spam (ham). The algorithm learns to identify patterns in the text, such as certain keywords or phrases, that are indicative of spam or non-spam.\n",
    "\n",
    "Classification: When a new email arrives, the Naïve Bayes classifier calculates the probability that the email is spam and the probability that it is non-spam based on the observed words or features. It then classifies the email as spam or non-spam based on which probability is higher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-software",
   "metadata": {},
   "source": [
    "iii) Market Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-wound",
   "metadata": {},
   "source": [
    "Market sentiment analysis involves assessing the sentiment or mood of financial markets or individual assets (e.g., stocks or cryptocurrencies). Naïve Bayes can be used for sentiment analysis in financial markets in the following way:\n",
    "\n",
    "Data Collection: Collect textual data from various sources, such as news articles, social media, and financial reports, that may contain information related to financial markets or specific assets.\n",
    "\n",
    "Sentiment Labeling: Manually or using automated sentiment analysis tools, label the collected data as positive, negative, or neutral sentiment regarding the market or the asset in question.\n",
    "\n",
    "Training: Train a Naïve Bayes classifier on the labeled data to learn the relationships between the textual features and the sentiment labels.\n",
    "\n",
    "Prediction: Use the trained classifier to analyze new textual data related to the market or asset. The classifier will estimate the probability of positive, negative, or neutral sentiment, helping investors and traders make more informed decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
